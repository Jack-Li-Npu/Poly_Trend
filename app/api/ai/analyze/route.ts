import { NextRequest, NextResponse } from "next/server";

export const maxDuration = 60; // Vercel Hobby è®¡åˆ’ä¸Šé™ä¸º 60 ç§’
export const dynamic = 'force-dynamic';

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { model, apiKey, query, markets, timestamp, tagsUsed, searchSource, geminiBaseUrl } = body;
    let { statistics } = body;

    // å¦‚æœå‰ç«¯æ²¡æœ‰ä¼ é€’ç»Ÿè®¡ä¿¡æ¯ï¼Œåˆ™åœ¨æ­¤å¤„è®¡ç®—
    if (!statistics) {
      console.log("ğŸ“Š è®¡ç®—å¸‚åœºç»Ÿè®¡ä¿¡æ¯...");
      const totalVolume = markets.reduce((sum: number, m: any) => {
        // è§£æ volume å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "$1.2M", "$500K", "$100"
        let val = 0;
        if (typeof m.volume === 'number') {
          val = m.volume;
        } else if (typeof m.volume === 'string') {
          const clean = m.volume.replace('$', '').replace(/,/g, '');
          if (clean.endsWith('M')) {
            val = parseFloat(clean) * 1000000;
          } else if (clean.endsWith('K')) {
            val = parseFloat(clean) * 1000;
          } else {
            val = parseFloat(clean) || 0;
          }
        }
        return sum + val;
      }, 0);

      const averageProbability = markets.length > 0
        ? markets.reduce((sum: number, m: any) => sum + (m.probability || 0), 0) / markets.length / 100
        : 0;

      const highConfidenceMarkets = markets.filter((m: any) => (m.probability || 0) > 80 || (m.probability || 0) < 20).length;

      statistics = {
        totalVolume,
        averageProbability,
        highConfidenceMarkets
      };
      console.log("âœ… ç»Ÿè®¡ä¿¡æ¯è®¡ç®—å®Œæˆ:", statistics);
    }

    console.log("ğŸ“¦ [PACKAGED DATA FOR AI ANALYSIS]");
    console.log(JSON.stringify({
      query,
      model,
      marketCount: markets.length,
      statistics,
      markets: markets.map((m: any) => ({
        title: m.title,
        probability: m.probability,
        outcome: m.outcome,
        volume: m.volume,
        outcomes: m.outcomes
      }))
    }, null, 2));

    console.log(`ğŸ¤– ä½¿ç”¨æ¨¡å‹ ${model} è¿›è¡ŒAIåˆ†æ...`);

    // æ ¹æ®ä¸åŒæ¨¡å‹è°ƒç”¨ä¸åŒçš„API
    let analysisResult;
    
    switch (model) {
      case "gemini":
        analysisResult = await analyzeWithGemini(apiKey, query, markets, statistics, geminiBaseUrl);
        break;
      
      case "claude":
        analysisResult = await analyzeWithClaude(apiKey, query, markets, statistics);
        break;
      
      case "chatgpt":
        analysisResult = await analyzeWithChatGPT(apiKey, query, markets, statistics);
        break;
      
      default:
        throw new Error(`ä¸æ”¯æŒçš„æ¨¡å‹: ${model}`);
    }

    return NextResponse.json({
      success: true,
      analysis: analysisResult,
      model,
      timestamp: new Date().toISOString(),
    });

  } catch (error) {
    console.error("AIåˆ†æé”™è¯¯:", error);
    return NextResponse.json(
      {
        success: false,
        error: error instanceof Error ? error.message : "AIåˆ†æå¤±è´¥",
      },
      { status: 500 }
    );
  }
}

// Gemini API åˆ†æ
async function analyzeWithGemini(apiKey: string, query: string, markets: any[], statistics: any, baseUrl?: string) {
  // è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ä¾› callGeminiAPI ä½¿ç”¨
  if (apiKey) process.env.GEMINI_API_KEY = apiKey;
  if (baseUrl) process.env.GEMINI_BASE_URL = baseUrl;

  const { callGeminiAPI } = await import("@/lib/gemini");

  const prompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¸‚åœºåˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹Polymarketé¢„æµ‹å¸‚åœºæ•°æ®ã€‚
æ•°æ®åŒ…å«æœç´¢æŸ¥è¯¢çš„ç›´æ¥ç»“æœï¼ˆç¡¬åŒ¹é…ï¼‰ä»¥åŠå¤šä¸ªç›¸å…³é¢†åŸŸçš„ç²¾é€‰å¸‚åœºï¼ˆæ ‡ç­¾ç²¾é€‰ï¼‰ã€‚

æŸ¥è¯¢: ${query}
åˆ†æå¸‚åœºæ€»æ•°: ${markets.length}
æ€»äº¤æ˜“é‡: $${statistics.totalVolume.toLocaleString()}
å¹³å‡æ¦‚ç‡: ${(statistics.averageProbability * 100).toFixed(1)}%
é«˜ç½®ä¿¡åº¦å¸‚åœº: ${statistics.highConfidenceMarkets}

ä»¥ä¸‹æ˜¯å®Œæ•´çš„é¢„æµ‹å¸‚åœºæ•´åˆæ•°æ® (JSON æ ¼å¼):
${JSON.stringify(markets.map((m: any) => ({
  title: m.title,
  probability: `${(m.probability).toFixed(1)}%`,
  volume: m.volume,
  category_context: m.reasoning || "æœç´¢ç›´è¾¾"
})), null, 2)}

è¯·æ ¹æ®ä¸Šè¿°æ•´åˆäº†å¤šç»´æ ‡ç­¾çš„æ•°æ®æä¾›ä¸€ä»½æ·±åº¦åˆ†ææŠ¥å‘Šï¼š
1. **å®è§‚å¸‚åœºæƒ…ç»ª**: ç»“åˆç¡¬åŒ¹é…ä¸å¤šç»´æ ‡ç­¾æ•°æ®ï¼Œåˆ†ææ•´ä½“è¶‹åŠ¿ã€‚
2. **å¤šç»´åº¦å‘ç°**: 
   - è¯†åˆ«ä¸åŒæ ‡ç­¾é¢†åŸŸï¼ˆå¦‚ Crypto, Politics, Tech ç­‰ï¼‰ä¹‹é—´çš„å…³è”ã€‚
   - æŒ‘é€‰ 3-5 ä¸ªæœ€å…·ä»£è¡¨æ€§æˆ–å¼‚å¸¸çš„å¸‚åœºã€‚
3. **é£é™©ä¸ä¸ç¡®å®šæ€§**: è¯„ä¼°å½“å‰æ•°æ®çš„å¯ä¿¡åº¦åŠæ½œåœ¨æ³¢åŠ¨é£é™©ã€‚
4. **å†³ç­–/ç­–ç•¥å»ºè®®**: åŸºäºæ•°æ®çš„ä¸€ä½“åŒ–ç­–ç•¥å»ºè®®ã€‚

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä½¿ç”¨ä¸“ä¸šçš„ Markdown æ ¼å¼ã€‚`;

  return await callGeminiAPI(prompt);
}

// Claude API åˆ†æ
async function analyzeWithClaude(apiKey: string, query: string, markets: any[], statistics: any) {
  const response = await fetch("https://api.anthropic.com/v1/messages", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "x-api-key": apiKey,
      "anthropic-version": "2023-06-01",
    },
    body: JSON.stringify({
      model: "claude-3-5-sonnet-20241022",
      max_tokens: 4096,
      messages: [
        {
          role: "user",
          content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¸‚åœºåˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹Polymarketé¢„æµ‹å¸‚åœºæ•°æ®ï¼š

æŸ¥è¯¢: ${query}
å¸‚åœºæ•°é‡: ${markets.length}
æ€»äº¤æ˜“é‡: $${statistics.totalVolume.toLocaleString()}
å¹³å‡æ¦‚ç‡: ${(statistics.averageProbability * 100).toFixed(1)}%
é«˜ç½®ä¿¡åº¦å¸‚åœº: ${statistics.highConfidenceMarkets}

ä»¥ä¸‹æ˜¯å®Œæ•´çš„é¢„æµ‹å¸‚åœºæ•°æ® (JSON æ ¼å¼):
${JSON.stringify(markets.map((m: any) => ({
  ...m,
  probability: `${(m.probability * 100).toFixed(1)}%` // åœ¨ Prompt ä¸­è½¬å›ç™¾åˆ†æ¯”æ–¹ä¾¿ AI é˜…è¯»
})), null, 2)}

è¯·æ ¹æ®ä¸Šè¿°å®Œæ•´æ•°æ®æä¾›ï¼š
1. **å¸‚åœºè¶‹åŠ¿åˆ†æ**: æ•´ä½“å¸‚åœºæƒ…ç»ªå’Œè¶‹åŠ¿
2. **å…³é”®å‘ç°**: æœ€å€¼å¾—å…³æ³¨çš„3-5ä¸ªå¸‚åœºåŠåŸå› 
3. **é£é™©æç¤º**: æ½œåœ¨é£é™©å’Œä¸ç¡®å®šå› ç´ 
4. **æŠ•èµ„å»ºè®®**: åŸºäºæ•°æ®çš„ç­–ç•¥å»ºè®®

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä½¿ç”¨Markdownæ ¼å¼ã€‚`,
        },
      ],
    }),
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`Claude APIé”™è¯¯: ${error}`);
  }

  const data = await response.json();
  return data.content[0].text;
}

// ChatGPT API åˆ†æ
async function analyzeWithChatGPT(apiKey: string, query: string, markets: any[], statistics: any) {
  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: "gpt-4-turbo-preview",
      messages: [
        {
          role: "system",
          content: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¸‚åœºåˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æé¢„æµ‹å¸‚åœºæ•°æ®å¹¶æä¾›æŠ•èµ„å»ºè®®ã€‚",
        },
        {
          role: "user",
          content: `è¯·åˆ†æä»¥ä¸‹Polymarketé¢„æµ‹å¸‚åœºæ•°æ®ï¼š

æŸ¥è¯¢: ${query}
å¸‚åœºæ•°é‡: ${markets.length}
æ€»äº¤æ˜“é‡: $${statistics.totalVolume.toLocaleString()}
å¹³å‡æ¦‚ç‡: ${(statistics.averageProbability * 100).toFixed(1)}%
é«˜ç½®ä¿¡åº¦å¸‚åœº: ${statistics.highConfidenceMarkets}

ä»¥ä¸‹æ˜¯å®Œæ•´çš„é¢„æµ‹å¸‚åœºæ•°æ® (JSON æ ¼å¼):
${JSON.stringify(markets.map((m: any) => ({
  ...m,
  probability: `${(m.probability * 100).toFixed(1)}%` // åœ¨ Prompt ä¸­è½¬å›ç™¾åˆ†æ¯”æ–¹ä¾¿ AI é˜…è¯»
})), null, 2)}

è¯·æ ¹æ®ä¸Šè¿°å®Œæ•´æ•°æ®æä¾›ï¼š
1. **å¸‚åœºè¶‹åŠ¿åˆ†æ**: æ•´ä½“å¸‚åœºæƒ…ç»ªå’Œè¶‹åŠ¿
2. **å…³é”®å‘ç°**: æœ€å€¼å¾—å…³æ³¨çš„3-5ä¸ªå¸‚åœºåŠåŸå› 
3. **é£é™©æç¤º**: æ½œåœ¨é£é™©å’Œä¸ç¡®å®šå› ç´ 
4. **æŠ•èµ„å»ºè®®**: åŸºäºæ•°æ®çš„ç­–ç•¥å»ºè®®

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä½¿ç”¨Markdownæ ¼å¼ã€‚`,
        },
      ],
      max_tokens: 2000,
      temperature: 0.7,
    }),
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`OpenAI APIé”™è¯¯: ${error}`);
  }

  const data = await response.json();
  return data.choices[0].message.content;
}
