import { NextRequest, NextResponse } from "next/server";

export const maxDuration = 60; // Vercel Hobby è®¡åˆ’ä¸Šé™ä¸º 60 ç§’
export const dynamic = 'force-dynamic';

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { model, apiKey, query, markets, timestamp, tagsUsed, searchSource, statistics } = body;

    console.log("ğŸ“¦ [PACKAGED DATA FOR AI ANALYSIS]");
    console.log(JSON.stringify({
      query,
      model,
      marketCount: markets.length,
      statistics,
      markets: markets.map((m: any) => ({
        title: m.title,
        probability: m.probability,
        outcome: m.outcome,
        volume: m.volume,
        outcomes: m.outcomes
      }))
    }, null, 2));

    console.log(`ğŸ¤– ä½¿ç”¨æ¨¡å‹ ${model} è¿›è¡ŒAIåˆ†æ...`);

    // æ ¹æ®ä¸åŒæ¨¡å‹è°ƒç”¨ä¸åŒçš„API
    let analysisResult;
    
    switch (model) {
      case "gemini":
        analysisResult = await analyzeWithGemini(apiKey, query, markets, statistics);
        break;
      
      case "claude":
        analysisResult = await analyzeWithClaude(apiKey, query, markets, statistics);
        break;
      
      case "chatgpt":
        analysisResult = await analyzeWithChatGPT(apiKey, query, markets, statistics);
        break;
      
      default:
        throw new Error(`ä¸æ”¯æŒçš„æ¨¡å‹: ${model}`);
    }

    return NextResponse.json({
      success: true,
      analysis: analysisResult,
      model,
      timestamp: new Date().toISOString(),
    });

  } catch (error) {
    console.error("AIåˆ†æé”™è¯¯:", error);
    return NextResponse.json(
      {
        success: false,
        error: error instanceof Error ? error.message : "AIåˆ†æå¤±è´¥",
      },
      { status: 500 }
    );
  }
}

// Gemini API åˆ†æ
async function analyzeWithGemini(apiKey: string, query: string, markets: any[], statistics: any) {
  const { GoogleGenerativeAI } = await import("@google/generative-ai");
  const genAI = new GoogleGenerativeAI(apiKey);
  // ä½¿ç”¨ç”¨æˆ·ç¡®è®¤æœ‰æ•ˆçš„æ¨¡å‹åç§°
  const model = genAI.getGenerativeModel({ model: "gemini-flash-lite-latest" });

  const prompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¸‚åœºåˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹Polymarketé¢„æµ‹å¸‚åœºæ•°æ®ï¼š

æŸ¥è¯¢: ${query}
å¸‚åœºæ•°é‡: ${markets.length}
æ€»äº¤æ˜“é‡: $${statistics.totalVolume.toLocaleString()}
å¹³å‡æ¦‚ç‡: ${(statistics.averageProbability * 100).toFixed(1)}%
é«˜ç½®ä¿¡åº¦å¸‚åœº: ${statistics.highConfidenceMarkets}

ä»¥ä¸‹æ˜¯å®Œæ•´çš„é¢„æµ‹å¸‚åœºæ•°æ® (JSON æ ¼å¼):
${JSON.stringify(markets.map((m: any) => ({
  ...m,
  probability: `${(m.probability * 100).toFixed(1)}%` // åœ¨ Prompt ä¸­è½¬å›ç™¾åˆ†æ¯”æ–¹ä¾¿ AI é˜…è¯»
})), null, 2)}

è¯·æ ¹æ®ä¸Šè¿°å®Œæ•´æ•°æ®æä¾›ï¼š
1. **å¸‚åœºè¶‹åŠ¿åˆ†æ**: æ•´ä½“å¸‚åœºæƒ…ç»ªå’Œè¶‹åŠ¿
2. **å…³é”®å‘ç°**: æœ€å€¼å¾—å…³æ³¨çš„3-5ä¸ªå¸‚åœºåŠåŸå› 
3. **é£é™©æç¤º**: æ½œåœ¨é£é™©å’Œä¸ç¡®å®šå› ç´ 
4. **æŠ•èµ„å»ºè®®**: åŸºäºæ•°æ®çš„ç­–ç•¥å»ºè®®

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä½¿ç”¨Markdownæ ¼å¼ã€‚`;

  const result = await model.generateContent(prompt);
  const response = await result.response;
  return response.text();
}

// Claude API åˆ†æ
async function analyzeWithClaude(apiKey: string, query: string, markets: any[], statistics: any) {
  const response = await fetch("https://api.anthropic.com/v1/messages", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "x-api-key": apiKey,
      "anthropic-version": "2023-06-01",
    },
    body: JSON.stringify({
      model: "claude-3-5-sonnet-20241022",
      max_tokens: 4096,
      messages: [
        {
          role: "user",
          content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¸‚åœºåˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹Polymarketé¢„æµ‹å¸‚åœºæ•°æ®ï¼š

æŸ¥è¯¢: ${query}
å¸‚åœºæ•°é‡: ${markets.length}
æ€»äº¤æ˜“é‡: $${statistics.totalVolume.toLocaleString()}
å¹³å‡æ¦‚ç‡: ${(statistics.averageProbability * 100).toFixed(1)}%
é«˜ç½®ä¿¡åº¦å¸‚åœº: ${statistics.highConfidenceMarkets}

ä»¥ä¸‹æ˜¯å®Œæ•´çš„é¢„æµ‹å¸‚åœºæ•°æ® (JSON æ ¼å¼):
${JSON.stringify(markets.map((m: any) => ({
  ...m,
  probability: `${(m.probability * 100).toFixed(1)}%` // åœ¨ Prompt ä¸­è½¬å›ç™¾åˆ†æ¯”æ–¹ä¾¿ AI é˜…è¯»
})), null, 2)}

è¯·æ ¹æ®ä¸Šè¿°å®Œæ•´æ•°æ®æä¾›ï¼š
1. **å¸‚åœºè¶‹åŠ¿åˆ†æ**: æ•´ä½“å¸‚åœºæƒ…ç»ªå’Œè¶‹åŠ¿
2. **å…³é”®å‘ç°**: æœ€å€¼å¾—å…³æ³¨çš„3-5ä¸ªå¸‚åœºåŠåŸå› 
3. **é£é™©æç¤º**: æ½œåœ¨é£é™©å’Œä¸ç¡®å®šå› ç´ 
4. **æŠ•èµ„å»ºè®®**: åŸºäºæ•°æ®çš„ç­–ç•¥å»ºè®®

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä½¿ç”¨Markdownæ ¼å¼ã€‚`,
        },
      ],
    }),
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`Claude APIé”™è¯¯: ${error}`);
  }

  const data = await response.json();
  return data.content[0].text;
}

// ChatGPT API åˆ†æ
async function analyzeWithChatGPT(apiKey: string, query: string, markets: any[], statistics: any) {
  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: "gpt-4-turbo-preview",
      messages: [
        {
          role: "system",
          content: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¸‚åœºåˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æé¢„æµ‹å¸‚åœºæ•°æ®å¹¶æä¾›æŠ•èµ„å»ºè®®ã€‚",
        },
        {
          role: "user",
          content: `è¯·åˆ†æä»¥ä¸‹Polymarketé¢„æµ‹å¸‚åœºæ•°æ®ï¼š

æŸ¥è¯¢: ${query}
å¸‚åœºæ•°é‡: ${markets.length}
æ€»äº¤æ˜“é‡: $${statistics.totalVolume.toLocaleString()}
å¹³å‡æ¦‚ç‡: ${(statistics.averageProbability * 100).toFixed(1)}%
é«˜ç½®ä¿¡åº¦å¸‚åœº: ${statistics.highConfidenceMarkets}

ä»¥ä¸‹æ˜¯å®Œæ•´çš„é¢„æµ‹å¸‚åœºæ•°æ® (JSON æ ¼å¼):
${JSON.stringify(markets.map((m: any) => ({
  ...m,
  probability: `${(m.probability * 100).toFixed(1)}%` // åœ¨ Prompt ä¸­è½¬å›ç™¾åˆ†æ¯”æ–¹ä¾¿ AI é˜…è¯»
})), null, 2)}

è¯·æ ¹æ®ä¸Šè¿°å®Œæ•´æ•°æ®æä¾›ï¼š
1. **å¸‚åœºè¶‹åŠ¿åˆ†æ**: æ•´ä½“å¸‚åœºæƒ…ç»ªå’Œè¶‹åŠ¿
2. **å…³é”®å‘ç°**: æœ€å€¼å¾—å…³æ³¨çš„3-5ä¸ªå¸‚åœºåŠåŸå› 
3. **é£é™©æç¤º**: æ½œåœ¨é£é™©å’Œä¸ç¡®å®šå› ç´ 
4. **æŠ•èµ„å»ºè®®**: åŸºäºæ•°æ®çš„ç­–ç•¥å»ºè®®

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä½¿ç”¨Markdownæ ¼å¼ã€‚`,
        },
      ],
      max_tokens: 2000,
      temperature: 0.7,
    }),
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`OpenAI APIé”™è¯¯: ${error}`);
  }

  const data = await response.json();
  return data.choices[0].message.content;
}
